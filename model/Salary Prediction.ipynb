{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7628e4d3-9a9d-40f7-b203-4849c0eccf0d",
   "metadata": {},
   "source": [
    "\n",
    "The Salary Dataset contains **6704 rows** and **6 columns** containing the following data:\n",
    "\n",
    "1. **Age**\n",
    "2. **Gender**\n",
    "3. **Education Level**\n",
    "4. **Job Title**\n",
    "5. **Years of Experience**\n",
    "6. **Salary**\n",
    "\n",
    "First we pre-process, clean and model the data to standarsise and structure it.\n",
    "\n",
    "\n",
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd3c813-2c9e-44bd-8356-dc6e40f0bb23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "### Suggestions for Improvement\n",
    "\n",
    "1. **Documentation:**\n",
    "   - Add detailed descriptions and docstrings to the code.\n",
    "   - Provide a few example datasets or a link to where they can be obtained.\n",
    "\n",
    "2. **Testing:**\n",
    "   - Include unit tests for different components of the project.\n",
    "\n",
    "3. **Error Handling:**\n",
    "   - Add error handling for common issues (e.g., missing files, incorrect data formats).\n",
    "\n",
    "4. **Enhance the GUI:**\n",
    "   - Improve the GUI for better user experience.\n",
    "\n",
    "5. **Project Automation:**\n",
    "   - Add CI/CD pipelines to automate testing and deployment.\n",
    "\n",
    "6. **Code Quality:**\n",
    "   - Ensure code adheres to PEP8 standards.\n",
    "```\n",
    "\n",
    "**Next steps:**\n",
    "**a.** Add unit tests for the `app.py` script.\n",
    "**b.** Enhance the GUI with additional features for better usability.\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_error "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b15f9f2-9250-4b45-aa62-6007ac9b3299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Data\n",
    "\n",
    "df = pd.read_csv(r'../dataset/Salary_Data.csv')\n",
    "# Dropping null values from database\n",
    "df.dropna(inplace=True)\n",
    "# Checking unique value counts of Job Titles in the database\n",
    "# print(df['Job Title'].value_counts())\n",
    "\n",
    "# Reducing Job titles by omitting titles with less than 25 counts\n",
    "\n",
    "job_title_count = df['Job Title'].value_counts()\n",
    "job_title_edited = job_title_count[job_title_count<=25]\n",
    "job_title_edited.count()\n",
    "\n",
    "# Omitting titles with less than 25 counts\n",
    "\n",
    "df['Job Title'] = df['Job Title'].apply(lambda x: 'Others' if x in job_title_edited else x )\n",
    "print(df['Job Title'].to_list())\n",
    "# print(df.head())\n",
    "\n",
    "#Checking unique value count of Education Level\n",
    "\n",
    "df['Education Level'].value_counts()\n",
    "\n",
    "# Combining repeating values of education level\n",
    "\n",
    "df['Education Level'].replace([\"Bachelor's Degree\",\"Master's Degree\",\"phD\"],[\"Bachelor's\",\"Master's\",\"PhD\"],inplace=True)\n",
    "df['Education Level'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce68c30-cdb2-4d65-81a0-72cd72127dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dummies for Job titles\n",
    "dummies = pd.get_dummies(df['Job Title'],drop_first=True)\n",
    "df = pd.concat([df,dummies],axis=1)\n",
    "\n",
    "# Drop Job Title column\n",
    "df.drop('Job Title',inplace=True,axis=1)\n",
    "# Label encoding the categorical variable\n",
    "le = LabelEncoder()\n",
    "df['Gender'] = le.fit_transform(df['Gender'])\n",
    "# Mapping Education Level column\n",
    "education_mapping = {\"High School\": 0, \"Bachelor's\": 1, \"Master's\": 2, \"PhD\": 3}\n",
    "df['Education Level'] = df['Education Level'].map(education_mapping)\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0581ea35",
   "metadata": {},
   "source": [
    "**Predicting Salary**\n",
    "\n",
    "3 Models will be used to predict the salary\n",
    "\n",
    "1. Linear Regression\n",
    "2. Deision Tree\n",
    "3. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2832ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# detecting the outliers in salary column using IQR method\n",
    "Q1 = df.Salary.quantile(0.25) # First Quartile\n",
    "Q3 = df.Salary.quantile(0.75) # Third Quartile\n",
    "\n",
    "# Caltulation Interquartile\n",
    "IQR = Q3-Q1\n",
    "\n",
    "# Deetecting outliers lying 1.5x of IQR above and below Q1 and Q3 resp\n",
    "lower = Q1-1.5*IQR\n",
    "upper = Q3+1.5*IQR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff41fa37",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.Salary>upper]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603b8515",
   "metadata": {},
   "source": [
    "**No outliers in Q3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7563ed91",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.Salary<lower]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9310e08e",
   "metadata": {},
   "source": [
    "**No outliers in Q1**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7025b8ec-3abb-4415-a7e8-c67c921fb7ec",
   "metadata": {},
   "source": [
    "<h2>Preparing the data for ML analysis by converting categorical job titles into a numerical format<h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3223e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating the dataset into features and target\n",
    "\n",
    "# Dataset conntaining all features(X) from df\n",
    "X = df.drop('Salary',axis=1)\n",
    "\n",
    "# Series containing target(Y) variable to be predicted\n",
    "Y= df['Salary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c3971d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data into 25% training and 75% test sets\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(X,Y,test_size=0.25,random_state=42)\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e20ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary for defining models and tuning hyperparameters\n",
    "\n",
    "model_params = {\n",
    "    'Linear_Regression':{\n",
    "        'model':LinearRegression(),\n",
    "        'params':{\n",
    "            \n",
    "        }\n",
    "    },\n",
    "    'Decision_Tree':{\n",
    "        'model':DecisionTreeRegressor(),\n",
    "        'params':{\n",
    "            'max_depth':[2,4,6,8,10],\n",
    "            'random_state':[0,42],\n",
    "            'min_samples_split':[1,5,10,20]\n",
    "        }\n",
    "    },\n",
    "    'Random_Forest':{\n",
    "        'model':RandomForestRegressor(),\n",
    "        'params':{\n",
    "            'n_estimators':[10,30,20,50,80]\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a4b23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper parameter tuning through grid search cv\n",
    "score=[]\n",
    "\n",
    "for model_name,m in model_params.items():\n",
    "    clf = GridSearchCV(m['model'],m['params'],cv=5,scoring='neg_mean_squared_error')\n",
    "    clf.fit(x_train,y_train)\n",
    "    \n",
    "    score.append({\n",
    "        'Model':model_name,\n",
    "        'Params':clf.best_params_,\n",
    "        'MSE(-ve)':clf.best_score_\n",
    "    })\n",
    "pd.DataFrame(score)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e5bbcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Order of the best models \n",
    "\n",
    "s = pd.DataFrame(score)\n",
    "sort = s.sort_values(by = 'MSE(-ve)',ascending=False)\n",
    "sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32083cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest model\n",
    "\n",
    "rfr = RandomForestRegressor(n_estimators=20)\n",
    "rfr.fit(x_train,y_train)\n",
    "print(x_train['Education Level'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c8067e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfr.score(x_test,y_test)\n",
    "x_test.head()\n",
    "y_test.head()\n",
    "        \n",
    "# y_test.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978922bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rfr = rfr.predict(x_test)\n",
    "\n",
    "print(\"Mean Squared Error :\",mean_squared_error(y_test,y_pred_rfr))\n",
    "print(\"Mean Absolute Error :\",mean_absolute_error(y_test,y_pred_rfr))\n",
    "print(\"Root Mean Squared Error :\",mean_squared_error(y_test,y_pred_rfr,squared=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96ed304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree model\n",
    "\n",
    "dtr = DecisionTreeRegressor(max_depth=10,min_samples_split=2,random_state=0)\n",
    "dtr.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a29307e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtr.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da68e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_dtr = dtr.predict(x_test)\n",
    "\n",
    "print(\"Mean Squared Error :\",mean_squared_error(y_test,y_pred_dtr))\n",
    "print(\"Mean Absolute Error :\",mean_absolute_error(y_test,y_pred_dtr))\n",
    "print(\"Root Mean Squared Error :\",mean_squared_error(y_test,y_pred_dtr,squared=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8f205c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear regression model\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc059a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66018d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lr = dtr.predict(x_test)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_pred_lr, y_test, color='blue', marker='o', alpha=0.7)\n",
    "plt.xlabel('predicted', fontsize=12)\n",
    "plt.ylabel('original', fontsize=12)\n",
    "plt.title('pridicted vs original')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(\"Mean Squared Error :\",mean_squared_error(y_test,y_pred_lr))\n",
    "print(\"Mean Absolute Error :\",mean_absolute_error(y_test,y_pred_lr))\n",
    "print(\"Root Mean Squared Error :\",mean_squared_error(y_test,y_pred_lr,squared=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ae86f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the feature importances of Random Forest Regressor\n",
    "feature_importances = rfr.feature_importances_\n",
    "\n",
    "# Assuming you have a list of feature names that corresponds to the feature importances\n",
    "feature_names = list(x_train.columns)\n",
    "\n",
    "# Sort feature importances in descending order\n",
    "sorted_indices = np.argsort(feature_importances)[::-1]\n",
    "sorted_feature_importances = [feature_importances[i] for i in sorted_indices]\n",
    "sorted_feature_names = [feature_names[i] for i in sorted_indices]\n",
    "\n",
    "# Create a bar chart\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.barh(sorted_feature_names[:10], sorted_feature_importances[:10])\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.title('Top 10 Feature Importance in Predicting Salary')\n",
    "plt.gca().invert_yaxis()  # Invert the y-axis for better visualization\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d23f66",
   "metadata": {},
   "source": [
    "**A bar chart depicting the importance of different features in predicting salary.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3571748d",
   "metadata": {},
   "source": [
    "<h2>Conclusion<h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ec26c5",
   "metadata": {},
   "source": [
    "**1. The Random Forest model achieved the highest R-squared score (0.971) and the lowest MSE, MAE, and RMSE values, indicating the best predictive performance among the three models.**\n",
    "\n",
    "**2. The Decision Tree model performed well with an R-squared score of 0.941 but had higher errors compared to the Random Forest.**\n",
    "\n",
    "**3. The Linear Regression model had the lowest R-squared score (0.833) and the highest errors, suggesting it may not capture the underlying patterns in the data as effectively as the ensemble models.**\n",
    "\n",
    "In conclusion, the Random Forest model appears to be the most suitable for predicting salaries in this dataset, as it offers the highest predictive accuracy and the lowest error metrics. Further optimization and fine-tuning of the Random Forest model could potentially lead to even better results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a715ca3",
   "metadata": {},
   "source": [
    "# Save the model\n",
    "save the model in pkl file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba264af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! Saving the model as a pickle file !!!\n",
    "'''\n",
    "import pickle\n",
    "\n",
    "# save random forest model as a pickle file \n",
    "model_pkl_file = \"salary predictor(rfr).pkl\"  \n",
    "\n",
    "with open(model_pkl_file, 'wb') as file:  \n",
    "    pickle.dump(rfr, file)\n",
    "\n",
    "# save linear regression model as a pickle file \n",
    "model_pkl_file = \"salary predictor(lr).pkl\"  \n",
    "\n",
    "with open(model_pkl_file, 'wb') as file:  \n",
    "    pickle.dump(lr, file)\n",
    "    \n",
    "# save Decsion tree model as a pickle file \n",
    "    \n",
    "model_pkl_file = \"salary predictor(dtr).pkl\"  \n",
    "\n",
    "with open(model_pkl_file, 'wb') as file:  \n",
    "    pickle.dump(dtr, file)\n",
    "model_pkl_file = \"df.pkl\"  \n",
    "\n",
    "with open(model_pkl_file, 'wb') as file:  \n",
    "    pickle.dump(df, file)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d256e9-119b-4501-ae91-b92a6da15af4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML-Kernel",
   "language": "python",
   "name": "ml-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
